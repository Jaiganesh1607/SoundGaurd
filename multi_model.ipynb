{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8739ab27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ STAGE 2: MULTI-CLASS THREAT CLASSIFICATION (FIXED VERSION)\n",
      "===========================================================================\n",
      "üìÅ DATASET STRUCTURE CHECK:\n",
      "\n",
      "TRAIN Directory: C:\\Users\\Jaiganesh\\SoundGaurd\\data\\processed_data\\train\n",
      "  ‚úÖ non_threat: 2100 files\n",
      "  ‚úÖ threat/glass_break: 700 files\n",
      "  ‚úÖ threat/scream: 700 files\n",
      "  ‚úÖ threat/gunshot: 700 files\n",
      "  üìä TRAIN Total: 4200 files\n",
      "\n",
      "TEST Directory: C:\\Users\\Jaiganesh\\SoundGaurd\\data\\processed_data\\test\n",
      "  ‚úÖ non_threat: 900 files\n",
      "  ‚úÖ threat/glass_break: 300 files\n",
      "  ‚úÖ threat/scream: 300 files\n",
      "  ‚úÖ threat/gunshot: 300 files\n",
      "  üìä TEST Total: 1800 files\n",
      "\n",
      "üìä DATASET SUMMARY:\n",
      "   Train: 4200 files\n",
      "   Test: 1800 files\n",
      "   Grand Total: 6000 files\n",
      "\n",
      "===========================================================================\n",
      "üîä BUILDING 4-CLASS TRAINING DATASET...\n",
      "[INFO] Found 2100 non-threat files\n",
      "[INFO] Found 700 glass_break files\n",
      "[INFO] Found 700 scream files\n",
      "[INFO] Found 700 gunshot files\n",
      "[INFO] Summary - Threats: 2100, Non-threats: 2100\n",
      "[INFO] Total files: 4200\n",
      "[INFO] Processing 4200 files...\n",
      "[INFO] Processed 500/4200 files...\n",
      "[INFO] Processed 1000/4200 files...\n",
      "[INFO] Processed 1500/4200 files...\n",
      "[INFO] Processed 2000/4200 files...\n",
      "[INFO] Processed 2500/4200 files...\n",
      "[INFO] Processed 3000/4200 files...\n",
      "[INFO] Processed 3500/4200 files...\n",
      "[INFO] Processed 4000/4200 files...\n",
      "[INFO] Successfully processed 4200 files\n",
      "[INFO] Feature shape: (4200, 240)\n",
      "[INFO] Class 0 (non_threat): 2100 samples\n",
      "[INFO] Class 1 (glass_break): 700 samples\n",
      "[INFO] Class 2 (scream): 700 samples\n",
      "[INFO] Class 3 (gunshot): 700 samples\n",
      "\n",
      "===========================================================================\n",
      "ü§ñ TRAINING MULTI-CLASS MODELS...\n",
      "\n",
      "üîÑ Training LogisticRegression...\n",
      "\n",
      "=== Validation - LogisticRegression ===\n",
      "Overall Accuracy: 0.9921\n",
      "Macro Precision: 0.9881\n",
      "Macro Recall: 0.9897\n",
      "Macro F1-Score: 0.9889\n",
      "\n",
      "Confusion Matrix:\n",
      "Rows=True, Cols=Predicted\n",
      "           non_threat glass_break      scream     gunshot\n",
      "  non_threat:      314           0           1           0    \n",
      " glass_break:        0         104           0           1    \n",
      "      scream:        0           0         104           1    \n",
      "     gunshot:        0           1           1         103    \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_threat       1.00      1.00      1.00       315\n",
      " glass_break       0.99      0.99      0.99       105\n",
      "      scream       0.98      0.99      0.99       105\n",
      "     gunshot       0.98      0.98      0.98       105\n",
      "\n",
      "    accuracy                           0.99       630\n",
      "   macro avg       0.99      0.99      0.99       630\n",
      "weighted avg       0.99      0.99      0.99       630\n",
      "\n",
      "\n",
      "üîÑ Training RandomForest...\n",
      "\n",
      "=== Validation - RandomForest ===\n",
      "Overall Accuracy: 0.9746\n",
      "Macro Precision: 0.9633\n",
      "Macro Recall: 0.9619\n",
      "Macro F1-Score: 0.9625\n",
      "\n",
      "Confusion Matrix:\n",
      "Rows=True, Cols=Predicted\n",
      "           non_threat glass_break      scream     gunshot\n",
      "  non_threat:      315           0           0           0    \n",
      " glass_break:        1          96           2           6    \n",
      "      scream:        0           2         103           0    \n",
      "     gunshot:        0           3           2         100    \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_threat       1.00      1.00      1.00       315\n",
      " glass_break       0.95      0.91      0.93       105\n",
      "      scream       0.96      0.98      0.97       105\n",
      "     gunshot       0.94      0.95      0.95       105\n",
      "\n",
      "    accuracy                           0.97       630\n",
      "   macro avg       0.96      0.96      0.96       630\n",
      "weighted avg       0.97      0.97      0.97       630\n",
      "\n",
      "\n",
      "üîÑ Training MLP...\n",
      "\n",
      "=== Validation - MLP ===\n",
      "Overall Accuracy: 0.9857\n",
      "Macro Precision: 0.9794\n",
      "Macro Recall: 0.9817\n",
      "Macro F1-Score: 0.9802\n",
      "\n",
      "Confusion Matrix:\n",
      "Rows=True, Cols=Predicted\n",
      "           non_threat glass_break      scream     gunshot\n",
      "  non_threat:      313           0           2           0    \n",
      " glass_break:        0          99           2           4    \n",
      "      scream:        0           0         105           0    \n",
      "     gunshot:        0           0           1         104    \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_threat       1.00      0.99      1.00       315\n",
      " glass_break       1.00      0.94      0.97       105\n",
      "      scream       0.95      1.00      0.98       105\n",
      "     gunshot       0.96      0.99      0.98       105\n",
      "\n",
      "    accuracy                           0.99       630\n",
      "   macro avg       0.98      0.98      0.98       630\n",
      "weighted avg       0.99      0.99      0.99       630\n",
      "\n",
      "\n",
      "üîÑ Training LinearSVM...\n",
      "\n",
      "=== Validation - LinearSVM ===\n",
      "Overall Accuracy: 0.9937\n",
      "Macro Precision: 0.9907\n",
      "Macro Recall: 0.9952\n",
      "Macro F1-Score: 0.9929\n",
      "\n",
      "Confusion Matrix:\n",
      "Rows=True, Cols=Predicted\n",
      "           non_threat glass_break      scream     gunshot\n",
      "  non_threat:      312           2           1           0    \n",
      " glass_break:        0         105           0           0    \n",
      "      scream:        0           0         105           0    \n",
      "     gunshot:        0           1           0         104    \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_threat       1.00      0.99      1.00       315\n",
      " glass_break       0.97      1.00      0.99       105\n",
      "      scream       0.99      1.00      1.00       105\n",
      "     gunshot       1.00      0.99      1.00       105\n",
      "\n",
      "    accuracy                           0.99       630\n",
      "   macro avg       0.99      1.00      0.99       630\n",
      "weighted avg       0.99      0.99      0.99       630\n",
      "\n",
      "\n",
      "üèÜ BEST MODEL: LinearSVM\n",
      "   Validation Macro F1: 0.9929\n",
      "\n",
      "üîÑ Retraining LinearSVM on full training set...\n",
      "\n",
      "===========================================================================\n",
      "üß™ FINAL 4-CLASS TEST EVALUATION...\n",
      "[INFO] Found 900 non-threat files\n",
      "[INFO] Found 300 glass_break files\n",
      "[INFO] Found 300 scream files\n",
      "[INFO] Found 300 gunshot files\n",
      "[INFO] Summary - Threats: 900, Non-threats: 900\n",
      "[INFO] Total files: 1800\n",
      "[INFO] Processing 1800 files...\n",
      "[INFO] Processed 500/1800 files...\n",
      "[INFO] Processed 1000/1800 files...\n",
      "[INFO] Processed 1500/1800 files...\n",
      "[INFO] Successfully processed 1800 files\n",
      "[INFO] Feature shape: (1800, 240)\n",
      "[INFO] Class 0 (non_threat): 900 samples\n",
      "[INFO] Class 1 (glass_break): 300 samples\n",
      "[INFO] Class 2 (scream): 300 samples\n",
      "[INFO] Class 3 (gunshot): 300 samples\n",
      "\n",
      "=== üéØ FINAL 4-CLASS RESULTS ===\n",
      "Overall Accuracy: 0.9461\n",
      "Macro Precision: 0.9276\n",
      "Macro Recall: 0.9247\n",
      "Macro F1-Score: 0.9241\n",
      "\n",
      "Confusion Matrix:\n",
      "Rows=True, Cols=Predicted\n",
      "           non_threat glass_break      scream     gunshot\n",
      "  non_threat:      890           5           4           1    \n",
      " glass_break:        1         275           4          20    \n",
      "      scream:        8          25         246          21    \n",
      "     gunshot:        1           4           3         292    \n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non_threat       0.99      0.99      0.99       900\n",
      " glass_break       0.89      0.92      0.90       300\n",
      "      scream       0.96      0.82      0.88       300\n",
      "     gunshot       0.87      0.97      0.92       300\n",
      "\n",
      "    accuracy                           0.95      1800\n",
      "   macro avg       0.93      0.92      0.92      1800\n",
      "weighted avg       0.95      0.95      0.95      1800\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "‚úÖ STAGE 2 COMPLETE!\n",
      "üìÅ Model saved: C:\\Users\\Jaiganesh\\SoundGaurd\\models_stage2\\stage2_multiclass_linearsvm.joblib\n",
      "üìÅ Config saved: C:\\Users\\Jaiganesh\\SoundGaurd\\models_stage2\\stage2_config.json\n",
      "üéØ 4-Class Accuracy: 94.6%\n",
      "üìä Dataset Size: 4200 train + 1800 test = 6000 total files\n",
      "üéØ Your SoundGuard can now identify specific threat types!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from joblib import dump, load\n",
    "\n",
    "# =========================\n",
    "# CONFIG - FIXED VERSION\n",
    "# =========================\n",
    "DATASET_TRAIN_DIR = r\"C:\\Users\\Jaiganesh\\SoundGaurd\\data\\processed_data\\train\"\n",
    "DATASET_TEST_DIR  = r\"C:\\Users\\Jaiganesh\\SoundGaurd\\data\\processed_data\\test\"\n",
    "MODEL_DIR         = r\"C:\\Users\\Jaiganesh\\SoundGaurd\\models_stage2\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Feature extraction parameters\n",
    "SR = 22050\n",
    "N_MFCC = 40\n",
    "N_FFT = 1024\n",
    "WIN_LENGTH = 512\n",
    "HOP_LENGTH = 256\n",
    "USE_DELTAS = True\n",
    "POOL_STATS = [\"mean\", \"std\"]\n",
    "\n",
    "# 4-class labels\n",
    "CLASS_NAMES = [\"non_threat\", \"glass_break\", \"scream\", \"gunshot\"]\n",
    "CLASS_MAPPING = {\n",
    "    \"non_threat\": 0,\n",
    "    \"glass_break\": 1, \n",
    "    \"scream\": 2,\n",
    "    \"gunshot\": 3\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# UTILITIES - FIXED VERSION\n",
    "# =========================\n",
    "def list_audio_files_multiclass(root_dir):\n",
    "    \"\"\"List all audio files with 4-class labels - FIXED VERSION\"\"\"\n",
    "    wavs = []\n",
    "    \n",
    "    if not os.path.isdir(root_dir):\n",
    "        print(f\"[ERROR] Root directory doesn't exist: {root_dir}\")\n",
    "        return wavs\n",
    "    \n",
    "    # Non-threat files (label = 0) - FIXED: avoid double counting\n",
    "    non_threat_path = os.path.join(root_dir, \"non_threat\")\n",
    "    if os.path.isdir(non_threat_path):\n",
    "        # Collect all unique WAV files (both .wav and .WAV)\n",
    "        all_non_threat_files = set()  # Use set to avoid duplicates\n",
    "        for ext in [\"*.wav\", \"*.WAV\"]:\n",
    "            pattern = os.path.join(non_threat_path, ext)\n",
    "            all_non_threat_files.update(glob.glob(pattern))\n",
    "        \n",
    "        all_non_threat_files = list(all_non_threat_files)  # Convert back to list\n",
    "        wavs.extend([(p, 0) for p in all_non_threat_files])\n",
    "        print(f\"[INFO] Found {len(all_non_threat_files)} non-threat files\")\n",
    "    else:\n",
    "        print(f\"[WARN] Non-threat directory missing: {non_threat_path}\")\n",
    "    \n",
    "    # Threat files (labels = 1, 2, 3) - FIXED: avoid double counting\n",
    "    threat_parent_path = os.path.join(root_dir, \"threat\")\n",
    "    if os.path.isdir(threat_parent_path):\n",
    "        for subfolder, label in [(\"glass_break\", 1), (\"scream\", 2), (\"gunshot\", 3)]:\n",
    "            subfolder_path = os.path.join(threat_parent_path, subfolder)\n",
    "            if os.path.isdir(subfolder_path):\n",
    "                # Collect all unique WAV files for this subfolder\n",
    "                all_threat_files = set()  # Use set to avoid duplicates\n",
    "                for ext in [\"*.wav\", \"*.WAV\"]:\n",
    "                    pattern = os.path.join(subfolder_path, ext)\n",
    "                    all_threat_files.update(glob.glob(pattern))\n",
    "                \n",
    "                all_threat_files = list(all_threat_files)  # Convert back to list\n",
    "                wavs.extend([(p, label) for p in all_threat_files])\n",
    "                print(f\"[INFO] Found {len(all_threat_files)} {subfolder} files\")\n",
    "            else:\n",
    "                print(f\"[WARN] {subfolder} directory missing: {subfolder_path}\")\n",
    "    else:\n",
    "        print(f\"[WARN] Threat parent directory missing: {threat_parent_path}\")\n",
    "    \n",
    "    # Final summary\n",
    "    total_threats = len([w for w in wavs if w[1] in [1, 2, 3]])\n",
    "    total_non_threats = len([w for w in wavs if w[1] == 0])\n",
    "    print(f\"[INFO] Summary - Threats: {total_threats}, Non-threats: {total_non_threats}\")\n",
    "    print(f\"[INFO] Total files: {len(wavs)}\")\n",
    "    \n",
    "    return wavs\n",
    "\n",
    "def extract_mfcc_features(wav_path):\n",
    "    \"\"\"Extract MFCC + deltas features (same as Stage 1)\"\"\"\n",
    "    try:\n",
    "        y, sr = sf.read(wav_path)\n",
    "        \n",
    "        if y.ndim > 1:\n",
    "            y = np.mean(y, axis=1)\n",
    "        \n",
    "        if sr != SR:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=SR)\n",
    "        \n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=y, sr=SR, n_mfcc=N_MFCC, n_fft=N_FFT,\n",
    "            hop_length=HOP_LENGTH, win_length=WIN_LENGTH\n",
    "        )\n",
    "        \n",
    "        feats = [mfcc]\n",
    "        \n",
    "        if USE_DELTAS:\n",
    "            delta = librosa.feature.delta(mfcc, order=1)\n",
    "            delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "            feats.extend([delta, delta2])\n",
    "        \n",
    "        F = np.vstack(feats)\n",
    "        \n",
    "        pooled = []\n",
    "        for stat in POOL_STATS:\n",
    "            if stat == \"mean\":\n",
    "                pooled.append(np.mean(F, axis=1))\n",
    "            elif stat == \"std\":\n",
    "                pooled.append(np.std(F, axis=1))\n",
    "        \n",
    "        pooled_vec = np.concatenate(pooled, axis=0)\n",
    "        return pooled_vec.astype(np.float32)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to process {wav_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def build_multiclass_dataset(root_dir):\n",
    "    \"\"\"Build 4-class dataset\"\"\"\n",
    "    items = list_audio_files_multiclass(root_dir)\n",
    "    \n",
    "    if len(items) == 0:\n",
    "        raise RuntimeError(f\"No audio files found in {root_dir}\")\n",
    "    \n",
    "    X, y, paths = [], [], []\n",
    "    failed_count = 0\n",
    "    \n",
    "    print(f\"[INFO] Processing {len(items)} files...\")\n",
    "    for i, (path, label) in enumerate(items):\n",
    "        if (i + 1) % 500 == 0:  # Progress indicator every 500 files\n",
    "            print(f\"[INFO] Processed {i + 1}/{len(items)} files...\")\n",
    "        \n",
    "        features = extract_mfcc_features(path)\n",
    "        if features is not None and np.all(np.isfinite(features)):\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "            paths.append(path)\n",
    "        else:\n",
    "            failed_count += 1\n",
    "    \n",
    "    if failed_count > 0:\n",
    "        print(f\"[WARN] Failed to process {failed_count} files\")\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        raise RuntimeError(f\"No valid features extracted from {len(items)} files\")\n",
    "    \n",
    "    X = np.vstack(X)\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "    \n",
    "    print(f\"[INFO] Successfully processed {len(X)} files\")\n",
    "    print(f\"[INFO] Feature shape: {X.shape}\")\n",
    "    \n",
    "    # Show class distribution\n",
    "    for i, class_name in enumerate(CLASS_NAMES):\n",
    "        count = np.sum(y == i)\n",
    "        print(f\"[INFO] Class {i} ({class_name}): {count} samples\")\n",
    "    \n",
    "    return X, y, paths\n",
    "\n",
    "def evaluate_multiclass(y_true, y_pred, title=\"\"):\n",
    "    \"\"\"Evaluate multi-class model performance\"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"Overall Accuracy: {acc:.4f}\")\n",
    "    print(f\"Macro Precision: {prec:.4f}\")\n",
    "    print(f\"Macro Recall: {rec:.4f}\")\n",
    "    print(f\"Macro F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"Rows=True, Cols=Predicted\")\n",
    "    print(\"         \", end=\"\")\n",
    "    for name in CLASS_NAMES:\n",
    "        print(f\"{name:>12}\", end=\"\")\n",
    "    print()\n",
    "    \n",
    "    for i, true_class in enumerate(CLASS_NAMES):\n",
    "        print(f\"{true_class:>12}: \", end=\"\")\n",
    "        for j in range(len(CLASS_NAMES)):\n",
    "            print(f\"{cm[i][j]:>8}\", end=\"    \")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
    "    \n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "# =========================\n",
    "# MAIN TRAINING\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéØ STAGE 2: MULTI-CLASS THREAT CLASSIFICATION (FIXED VERSION)\")\n",
    "    print(\"=\" * 75)\n",
    "    \n",
    "    # Check folder structure first\n",
    "    print(\"üìÅ DATASET STRUCTURE CHECK:\")\n",
    "    total_train_files = 0\n",
    "    total_test_files = 0\n",
    "    \n",
    "    for split, split_dir in [(\"TRAIN\", DATASET_TRAIN_DIR), (\"TEST\", DATASET_TEST_DIR)]:\n",
    "        print(f\"\\n{split} Directory: {split_dir}\")\n",
    "        split_total = 0\n",
    "        \n",
    "        if os.path.isdir(split_dir):\n",
    "            # Check non-threat\n",
    "            non_threat_path = os.path.join(split_dir, \"non_threat\")\n",
    "            if os.path.isdir(non_threat_path):\n",
    "                # Count unique files (both .wav and .WAV)\n",
    "                wav_files = set(glob.glob(os.path.join(non_threat_path, \"*.wav\")))\n",
    "                wav_files.update(glob.glob(os.path.join(non_threat_path, \"*.WAV\")))\n",
    "                count = len(wav_files)\n",
    "                print(f\"  ‚úÖ non_threat: {count} files\")\n",
    "                split_total += count\n",
    "            else:\n",
    "                print(f\"  ‚ùå non_threat: MISSING\")\n",
    "            \n",
    "            # Check threat subfolders\n",
    "            threat_path = os.path.join(split_dir, \"threat\")\n",
    "            if os.path.isdir(threat_path):\n",
    "                for subfolder in [\"glass_break\", \"scream\", \"gunshot\"]:\n",
    "                    subfolder_path = os.path.join(threat_path, subfolder)\n",
    "                    if os.path.isdir(subfolder_path):\n",
    "                        # Count unique files (both .wav and .WAV)\n",
    "                        wav_files = set(glob.glob(os.path.join(subfolder_path, \"*.wav\")))\n",
    "                        wav_files.update(glob.glob(os.path.join(subfolder_path, \"*.WAV\")))\n",
    "                        count = len(wav_files)\n",
    "                        print(f\"  ‚úÖ threat/{subfolder}: {count} files\")\n",
    "                        split_total += count\n",
    "                    else:\n",
    "                        print(f\"  ‚ùå threat/{subfolder}: MISSING\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå threat: MISSING\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Directory doesn't exist!\")\n",
    "        \n",
    "        print(f\"  üìä {split} Total: {split_total} files\")\n",
    "        if split == \"TRAIN\":\n",
    "            total_train_files = split_total\n",
    "        else:\n",
    "            total_test_files = split_total\n",
    "    \n",
    "    print(f\"\\nüìä DATASET SUMMARY:\")\n",
    "    print(f\"   Train: {total_train_files} files\")\n",
    "    print(f\"   Test: {total_test_files} files\")\n",
    "    print(f\"   Grand Total: {total_train_files + total_test_files} files\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 75)\n",
    "    print(\"üîä BUILDING 4-CLASS TRAINING DATASET...\")\n",
    "    X_train_full, y_train_full, train_paths = build_multiclass_dataset(DATASET_TRAIN_DIR)\n",
    "    \n",
    "    # Validation split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, \n",
    "        test_size=0.15, \n",
    "        random_state=42, \n",
    "        stratify=y_train_full\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 75)\n",
    "    print(\"ü§ñ TRAINING MULTI-CLASS MODELS...\")\n",
    "    \n",
    "    # Models for multi-class classification\n",
    "    models = {\n",
    "        \"LogisticRegression\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LogisticRegression(max_iter=2000, C=1.0, random_state=42))\n",
    "        ]),\n",
    "        \n",
    "        \"RandomForest\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "        ]),\n",
    "        \n",
    "        \"MLP\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", MLPClassifier(hidden_layer_sizes=(256, 128), max_iter=1000, random_state=42))\n",
    "        ]),\n",
    "        \n",
    "        \"LinearSVM\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"clf\", LinearSVC(C=1.0, random_state=42, max_iter=3000))\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Train and validate all models\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nüîÑ Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        results[name] = evaluate_multiclass(y_val, y_pred, f\"Validation - {name}\")\n",
    "    \n",
    "    # Select best model\n",
    "    best_name = max(results, key=lambda x: results[x][\"f1\"])\n",
    "    best_model = models[best_name]\n",
    "    \n",
    "    print(f\"\\nüèÜ BEST MODEL: {best_name}\")\n",
    "    print(f\"   Validation Macro F1: {results[best_name]['f1']:.4f}\")\n",
    "    \n",
    "    # Retrain on full training set\n",
    "    print(f\"\\nüîÑ Retraining {best_name} on full training set...\")\n",
    "    best_model.fit(X_train_full, y_train_full)\n",
    "    \n",
    "    # Final test evaluation\n",
    "    print(\"\\n\" + \"=\" * 75)\n",
    "    print(\"üß™ FINAL 4-CLASS TEST EVALUATION...\")\n",
    "    X_test, y_test, test_paths = build_multiclass_dataset(DATASET_TEST_DIR)\n",
    "    \n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    final_results = evaluate_multiclass(y_test, y_test_pred, \"üéØ FINAL 4-CLASS RESULTS\")\n",
    "    \n",
    "    # Save model and config\n",
    "    model_filename = f\"stage2_multiclass_{best_name.lower()}.joblib\"\n",
    "    model_path = os.path.join(MODEL_DIR, model_filename)\n",
    "    dump(best_model, model_path)\n",
    "    \n",
    "    config = {\n",
    "        \"model_type\": best_name,\n",
    "        \"model_path\": model_path,\n",
    "        \"feature_params\": {\n",
    "            \"sr\": SR,\n",
    "            \"n_mfcc\": N_MFCC,\n",
    "            \"n_fft\": N_FFT,\n",
    "            \"win_length\": WIN_LENGTH,\n",
    "            \"hop_length\": HOP_LENGTH,\n",
    "            \"use_deltas\": USE_DELTAS,\n",
    "            \"pool_stats\": POOL_STATS\n",
    "        },\n",
    "        \"results\": final_results,\n",
    "        \"class_names\": CLASS_NAMES,\n",
    "        \"class_mapping\": CLASS_MAPPING,\n",
    "        \"dataset_info\": {\n",
    "            \"train_files\": len(X_train_full),\n",
    "            \"test_files\": len(X_test),\n",
    "            \"total_files\": len(X_train_full) + len(X_test)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    config_path = os.path.join(MODEL_DIR, \"stage2_config.json\")\n",
    "    with open(config_path, \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 75)\n",
    "    print(\"‚úÖ STAGE 2 COMPLETE!\")\n",
    "    print(f\"üìÅ Model saved: {model_path}\")\n",
    "    print(f\"üìÅ Config saved: {config_path}\")\n",
    "    print(f\"üéØ 4-Class Accuracy: {final_results['accuracy']:.1%}\")\n",
    "    print(f\"üìä Dataset Size: {len(X_train_full)} train + {len(X_test)} test = {len(X_train_full) + len(X_test)} total files\")\n",
    "    print(f\"üéØ Your SoundGuard can now identify specific threat types!\")\n",
    "\n",
    "# Inference function for specific threat identification\n",
    "def predict_threat_type(wav_path, model_path, config_path):\n",
    "    \"\"\"Predict specific threat type for a WAV file\"\"\"\n",
    "    model = load(model_path)\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    features = extract_mfcc_features(wav_path)\n",
    "    if features is None:\n",
    "        return None, None\n",
    "    \n",
    "    features = features.reshape(1, -1)\n",
    "    prediction = model.predict(features)[0]\n",
    "    \n",
    "    # Get probability if available\n",
    "    probabilities = None\n",
    "    try:\n",
    "        if hasattr(model.named_steps['clf'], 'predict_proba'):\n",
    "            probabilities = model.named_steps['clf'].predict_proba(\n",
    "                model.named_steps['scaler'].transform(features)\n",
    "            )[0]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    predicted_class = config['class_names'][prediction]\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "# Example usage:\n",
    "# threat_type, probs = predict_threat_type(\"test.wav\", \"models_stage2/stage2_multiclass_logisticregression.joblib\", \"models_stage2/stage2_config.json\")\n",
    "# print(f\"Predicted threat: {threat_type}\")\n",
    "# if probs is not None:\n",
    "#     for i, class_name in enumerate(CLASS_NAMES):\n",
    "#         print(f\"  {class_name}: {probs[i]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
